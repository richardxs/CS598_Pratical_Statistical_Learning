{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prject_folder = \"~/Dropbox/UIUC_CS598_Statistical_Learning/CS598_Pratical_Statistical_Learning/Project3/proj3_data/split_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the training data and clean the html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(prject_folder, \"train.tsv\"), sep='\\t', header=0, dtype=str)\n",
    "df_test_x = pd.read_csv(os.path.join(prject_folder, \"test.tsv\"), sep='\\t', header=0, dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test_y = pd.read_csv(os.path.join(prject_folder, \"test_y.tsv\"),sep='\\t', header=0, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['review'] = df_train['review'].str.replace('&lt;.*?&gt;', ' ', regex=True)\n",
    "df_test_x['review'] = df_test_x['review'].str.replace('&lt;.*?&gt;', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_indices = df_train[df_train['sentiment']=='1'].index.values\n",
    "negaive_indices = df_train[df_train['sentiment']=='0'].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pos = len(positive_indices)\n",
    "num_neg = len(negaive_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Construct DT (DocumentTerm) matrix (maximum 4-grams). \n",
    "> The default vocabulary size (i.e., # of columns of dtm_train) is more than 30,000, bigger than the sample size n = 25,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"i\", \"me\", \"my\", \"myself\", \n",
    "               \"we\", \"our\", \"ours\", \"ourselves\", \n",
    "               \"you\", \"your\", \"yours\", \n",
    "               \"their\", \"they\", \"his\", \"her\", \n",
    "               \"she\", \"he\", \"a\", \"an\", \"and\",\n",
    "               \"is\", \"was\", \"are\", \"were\", \n",
    "               \"him\", \"himself\", \"has\", \"have\", \n",
    "               \"it\", \"its\", \"the\", \"us\"]\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    preprocessor=lambda x: x.lower(),  # Convert to lowercase\n",
    "    stop_words=stop_words,             # Remove stop words\n",
    "    ngram_range=(1, 4),               # Use 1- to 4-grams\n",
    "    min_df=0.001,                        # Minimum term frequency\n",
    "    max_df=0.5,                       # Maximum document frequency\n",
    "    token_pattern=r\"\\b[\\w+\\|']+\\b\" # Use word tokenizer: See Ethan's comment below\n",
    ")\n",
    "\n",
    "dtm_train = vectorizer.fit_transform(df_train['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_names = pd.DataFrame(vectorizer.get_feature_names_out(), columns=['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Two sample t-test calculation\n",
    "Filter the vocabulary to include only terms I could readily interpret. I employed a straightforward screening method: the two-sample t-test. This test compares one-dimensional observations from two groups, denoted as:$X_1, X_2, ..., X_m$, $Y_1, Y_2, ..., Y_n$\n",
    "\n",
    "The goal is to determine whether the X population and the Y population share the same mean. The two-sample t-statistic is computed as:\n",
    "$$\n",
    "\\frac{\\bar X - \\bar Y}{\\sqrt{\\frac{\\sigma_{X}^2}{m} + \\frac{\\sigma_{Y}^2}{n}}}\n",
    "$$\n",
    "where $\\sigma_{X}^2$, $\\sigma_{Y}^2$ denote the sample variance of $X$ and $Y$\n",
    "\n",
    "> Suppose we have $m$ positive reviews and $n$ negative reviews. For a given word, $X_i$'s represent the measurements associated with each of the positive reviews, and $Y_j$'s represent the measurements corresponding to each of the negative reviews. The goal is to assess the significance of differences in measurements between the two sentiment groups for each word via t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_train_array= dtm_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_statistics_array = np.zeros(len(df_features_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_features_names)):\n",
    "    # positive mean/variance\n",
    "    x_bar = np.mean(dtm_train_array[positive_indices, i])\n",
    "    x_var = np.var(dtm_train_array[positive_indices, i])\n",
    "\n",
    "    # negative mean/variance\n",
    "    y_bar = np.mean(dtm_train_array[negaive_indices, i])\n",
    "    y_var = np.var(dtm_train_array[negaive_indices, i])\n",
    "\n",
    "    t_statistics_array[i] = (x_bar - y_bar)/np.sqrt(x_var/num_pos + y_var/num_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_statistics_descending_array = t_statistics_array.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Top 50 **positive words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['great', 'excellent', 'best', 'of best', 'wonderful',\n",
       "       'one of best', 'perfect', 'love', 'amazing', 'superb', 'loved',\n",
       "       'beautiful', 'well', 'favorite', 'brilliant', 'life', 'must see',\n",
       "       'highly', 'also', 'very', 'fantastic', 'one of', 'performance',\n",
       "       'beautifully', 'both', 'always', 'enjoyed', 'wonderfully',\n",
       "       'very well', 'well worth', 'strong', 'today', '8 10',\n",
       "       'highly recommend', 'this great', 'performances', 'young',\n",
       "       'touching', '10 10', 'highly recommended', 'years', '7 10',\n",
       "       'powerful', 'perfectly', 'definitely', 'terrific', 'moving',\n",
       "       'love this', 'well as', '8'], dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_names['feature_names'].values[t_statistics_descending_array[:50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Top **Negative words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mess', 'pathetic', 'unless', 'laughable', 'annoying', 'dull',\n",
       "       'any', 'supposed to be', 'oh', 'waste time', 'thing', 'pointless',\n",
       "       'cheap', 'money', 'worst movie', 'script', \"don't\", 'wasted',\n",
       "       'lame', 'not even', 'waste of time', 'plot', 'ridiculous', 'avoid',\n",
       "       'why', 'supposed to', 'just', 'crap', 'poorly', 'at all',\n",
       "       'supposed', 'one of worst', 'so bad', 'acting', 'even', 'horrible',\n",
       "       'stupid', 'minutes', 'nothing', 'poor', 'of worst', 'boring', 'no',\n",
       "       'waste of', 'worse', 'terrible', 'awful', 'waste', 'worst', 'bad'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_names['feature_names'].values[t_statistics_descending_array[-50:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Select 2000 words with top absolute t_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_t_statistics_array = np.abs(t_statistics_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_t_stastics_descending_array_index = absolute_t_statistics_array.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vocab_2k = df_features_names['feature_names'].values[absolute_t_stastics_descending_array_index[:2000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: use Lasso (with logistic regression) to trim the vocabulary size iteratively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = LogisticRegression(penalty='l1', solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(ngram_range=(1, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(ngram_range=(1, 2))"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2k = CountVectorizer(\n",
    "    ngram_range=(1, 2)               # Use 1- to 4-grams\n",
    ")\n",
    "\n",
    "vectorizer2k.fit(selected_vocab_2k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_train2k = vectorizer2k.transform(df_train['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(-2, 1, 10)\n",
    "lass_models = []\n",
    "for alpha in alphas:\n",
    "    lasso_model = LogisticRegression(penalty='l1', solver='liblinear', C = alpha)\n",
    "    lasso_model.fit(X=dtm_train2k, y=df_train['sentiment'])\n",
    "    lass_models.append(lasso_model)\n",
    "\n",
    "tuned_parameters = [{'C': alphas}]\n",
    "n_folds = 5\n",
    "lasso_clf = GridSearchCV(lasso_model, [{'C': alphas}], cv=n_folds, refit=False, scoring='roc_auc')\n",
    "lasso_clf.fit(X=dtm_train2k, y=df_train['sentiment'])\n",
    "best_alpha = lasso_clf.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555493607259746"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46415888336127775"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {color: black;}#sk-container-id-30 pre{padding: 0;}#sk-container-id-30 div.sk-toggleable {background-color: white;}#sk-container-id-30 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-30 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-30 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-30 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-30 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-30 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-30 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-30 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-30 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-30 div.sk-item {position: relative;z-index: 1;}#sk-container-id-30 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-30 div.sk-item::before, #sk-container-id-30 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-30 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-30 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-30 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-30 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-30 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-30 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-30 div.sk-label-container {text-align: center;}#sk-container-id-30 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-30 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.19, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.19, penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.19, penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_lasso_model = LogisticRegression(penalty='l1', solver='liblinear', C = 0.19)\n",
    "best_lasso_model.fit(X=dtm_train2k, y=df_train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_model_coef = pd.DataFrame(np.squeeze(abs(best_lasso_model.coef_)), columns=['abs_coef']).sort_values(by=['abs_coef'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abs_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>1.712660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>1.671854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>1.490252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>1.467570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1.363797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.000993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>0.000912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>0.000756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>0.000492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>987 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abs_coef\n",
       "1027  1.712660\n",
       "1735  1.671854\n",
       "1817  1.490252\n",
       "977   1.467570\n",
       "596   1.363797\n",
       "...        ...\n",
       "309   0.000993\n",
       "1049  0.000912\n",
       "1509  0.000756\n",
       "1679  0.000492\n",
       "411   0.000346\n",
       "\n",
       "[987 rows x 1 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_model_coef[df_best_model_coef['abs_coef']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_indices = df_best_model_coef[df_best_model_coef['abs_coef']>0.0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_vocab = selected_vocab_2k[top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "987"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['surprisingly', 'dreams', 'without any', 'project', 'portrayal',\n",
       "       'cash in', 'to sit', 'rest of', 'worse than', 'film shows',\n",
       "       'release', 'unlike', 'to work with', 'doing', 'perfectly cast',\n",
       "       'musical', 'obvious', '0 10', 'original', 'br 9 10', 'only',\n",
       "       'br br worst', 'entertaining', 'excellent movie', 'br 1', 'do',\n",
       "       'worst', 'realistic', 'nothing to do with', 'spectacular',\n",
       "       'seriously', 'drivel', 'hooked', 'for no', 'even for', 'music',\n",
       "       'this gem', 'sounded', 'waste of time money', 'job',\n",
       "       'poorly acted', 'unintentional', '7 10', 'worst part', 'images',\n",
       "       'wasted time', 'avoid at all costs', 'spent', 'camcorder',\n",
       "       'that supposed to', 'neither', 'waste time with this',\n",
       "       'this great film', 'clichéd', 'avoid this movie', 'although',\n",
       "       'little film', '4 out of 10', 'disgusting', 'costs', 'notch',\n",
       "       'era', '90 minutes', 'only good thing about', 'br br 8 10',\n",
       "       'of worst movies ever', 'this piece of', 'delicate', 'point',\n",
       "       'that supposed', 'wasting time', 'review', 'what makes', 'intense',\n",
       "       \"don't bother\", 'side of', 'just terrible', '4 10', 'portrayal of',\n",
       "       'pleasantly surprised', 'mess', 'bit too', 'enjoyed this film',\n",
       "       'to be missed', 'seems', 'pathetic', '9 out of 10', 'as bad',\n",
       "       'movie so', 'or something', 'cinema', 'enough', 'but at least',\n",
       "       'excellent performances', 'horrid', 'worst ever', 'even get',\n",
       "       'delightful', 'total waste', \"i'm\", 'young man', 'william',\n",
       "       'bad acting', 'time on', 'nothing more than', 'insulting',\n",
       "       'any sort', 'wife', 'first of all', 'cast great', 'like watching',\n",
       "       'but this just', 'gore', 'make movie', 'low', 'definitely',\n",
       "       'of money', 'joy', 'fest', 'unique', 'raw', 'incoherent',\n",
       "       \"can't act\", 'ripped', 'this movie great', 'sucks', 'released',\n",
       "       'non existent', \"br br don't\", 'honestly', 'entire',\n",
       "       'one of all time', 'everyone should', \"didn't\", '3 out of 10',\n",
       "       'this garbage', 'fabulous', 'made no', 'gritty', '7',\n",
       "       'fell asleep', \"didn't care\", 'to believe that', 'of great',\n",
       "       'br br highly recommended', 'existent', \"it's like\", 'impact',\n",
       "       'stay away from this', 'movie terrible', 'anything to', 'meets',\n",
       "       'each of', '8 out of', 'film very', 'horror', 'year olds',\n",
       "       'dreadful', 'this horrible', 'genius', 'not even', 'br br 8',\n",
       "       'to cash in', 'of time money', 'feelings', 'stay away from',\n",
       "       'masterpiece', 'editing', 'mildly', 'straight to video', 'crappy',\n",
       "       'of movie', \"couldn't\", 'sub par', 'make', 'far worst',\n",
       "       'of best movies', 'same time', 'to be worst', 'way too much',\n",
       "       'see for', 'morons', 'especially in', 'to live', 'suck', 'times',\n",
       "       'academy', 'embarrassingly', 'loved this', 'stick', 'different',\n",
       "       'or', 'seemed to', 'lines', 'br br grade d', 'save', 'life in',\n",
       "       'dumbest', '20 minutes', 'unforgettable', 'boring br br',\n",
       "       'nothing more', 'low budget', 'about as', 'performance as',\n",
       "       'br br highly', 'supporting', 'mean', 'pretty', 'lifeless',\n",
       "       'one of all', 'first saw', 'loving', 'truly awful', 'gem',\n",
       "       'would not recommend', 'come up', 'dumb', '1 10', 'seen worse',\n",
       "       'man who', 'br film', 'especially', 'nowhere', 'if want to see',\n",
       "       'waste', 'going for', 'stay away', 'lack of', 'really wanted',\n",
       "       'splendid', 'role of', 'irritating', 'but also', 'on plus',\n",
       "       'nothing in', 'totally', 'laughably', 'emotions',\n",
       "       'watching paint dry', 'captured', 'writers', 'most of movie',\n",
       "       'sadness', 'worst movies', 'so real', 'positive',\n",
       "       \"of worst movies i've\", 'worst thing', 'try', 'extremely well',\n",
       "       'see', 'incompetent', 'bad that', \"worst movies i've ever\",\n",
       "       'award', 'to sit through', 'films of', 'may not be', 'this just',\n",
       "       'really wanted to', 'very well', 'no reason', 'landscape', 'won',\n",
       "       'compelling', 'stupid br', 'most boring', 'also very good',\n",
       "       'light', 'what hell', 'bore', 'this supposed', 'also excellent',\n",
       "       'should never', 'not worth', 'even', 'sitting through', 'idiots',\n",
       "       'boredom', 'redeeming', 'muddled', 'whatsoever', 'hilarious',\n",
       "       'later', 'looks like', 'obviously', 'br br if want',\n",
       "       'to see again', 'magnificent', \"it's not even\", 'tense',\n",
       "       'also great', 'lacks', 'greatest', 'experience', 'okay',\n",
       "       'funny or', 'feel good', 'as well as', 'desire', 'creates',\n",
       "       'perfect', 'or money', 'good thing', 'theme', 'this story',\n",
       "       'this crap', 'to be comedy', 'br 3', 'rent this', 'even remotely',\n",
       "       'excellent as', 'thin', 'be funny', 'be comedy', \"weren't\",\n",
       "       'stinker', 'cgi', 'to warn', 'real life', 'worst film', 'hours of',\n",
       "       'least bit', 'tells story', 'acting terrible', 'mst3k', 'flick',\n",
       "       'movie so bad', 'could been good', 'rubbish', 'yeah',\n",
       "       'of all time', 'on edge of', 'married',\n",
       "       'international film festival', 'br br 1', 'br 7', 'generic',\n",
       "       'for worst', 'time money', 'drama', 'this piece of crap', 'finds',\n",
       "       'favorites', 'not good', 'new', 'appreciated',\n",
       "       'complete waste of time', 'no point', 'miserably', 'pile of',\n",
       "       '4 out', 'what point of', 'appalling', 'story told',\n",
       "       'worst films ever', 'this could', 'brought to', 'minutes of',\n",
       "       'appreciate', 'effective', 'shows', '15 minutes', 'stinks',\n",
       "       'story about', 'sorry', 'very touching', \"don't watch\", 'sense at',\n",
       "       'waste time or', 'only positive', 'how not to', 'movie excellent',\n",
       "       'none', 'of time', 'some sort', '7 out of', 'to be',\n",
       "       'to perfection', 'for everyone', 'disappointment', 'br if want',\n",
       "       'seemed like', 'loved this movie', 'steals show', 'of trash',\n",
       "       'very much', 'great to see', 'do with', 'embarrassing', 'unfunny',\n",
       "       'excellent job', 'sit through this', 'riveting', 'looked like',\n",
       "       'good job', 'great movie', 'bland', 'horrible acting',\n",
       "       'bad script', 'no redeeming', 'rented this', 'story', 'will love',\n",
       "       'at same', 'want to', 'sake', 'wasted on', 'movie could',\n",
       "       \"i'm sorry\", \"doesn't even\", 'uninspired', 'avoid at all',\n",
       "       'natural', 'plays', 'warn', 'but then', 'just great', 'elegant',\n",
       "       'to sit through this', 'sucked', 'as one', 'do not waste',\n",
       "       'br if want to', 'wonderfully', 'become', 'laughable',\n",
       "       'this movie terrible', 'absolutely no', 'not very good',\n",
       "       'completely', 'that would', \"there's no\", 'bad but', 'great as',\n",
       "       'highly recommend this', 'in life', 'of most', 'solid',\n",
       "       'be missed', 'that this', 'making', 'br br 1 10', 'of young',\n",
       "       'simple but', 'bad actors', 'going', 'supporting cast', 'useless',\n",
       "       'painful', 'memories', 'excellent film', 'deeply', 'fi channel',\n",
       "       'so awful', 'finest', 'bad movies', 'terrible script',\n",
       "       'in many ways', 'to laugh at', 'stock footage', 'cover',\n",
       "       'soundtrack', 'oh', 'embarrassment', 'human', 'heartwarming',\n",
       "       '2 10', 'waste time on', 'saw this', 'by far worst', 'about only',\n",
       "       'exquisite', 'wooden', 'of favorite', 'first off', \"br don't\",\n",
       "       'shines', 'captivating', 'subtitles', 'insult to', 'got',\n",
       "       'complex', 'to do with', 'score by', 'inspiring', 'chick',\n",
       "       'money on this', 'why did', 'scary', 'this movie bad',\n",
       "       'unintentionally', 'cardboard', 'sat', 'on edge', 'no sense at',\n",
       "       'seagal', 'bad film', 'not enough to', \"don't miss\", 'lovely',\n",
       "       'really great', 'at all br', 'sense at all', 'might', 'classic',\n",
       "       'among', 'some kind', 'remotely', 'killed', 'holds up', 'if',\n",
       "       \"can't\", 'unexpected', 'cheesy', 'definitely recommend',\n",
       "       'excellently', 'trying to be', 'total', 'make any sense', 'just',\n",
       "       'terrible br br', 'very very bad', '30', 'top notch', 'rip',\n",
       "       'tragic', 'awesome', 'at all br br', \"don't even\", 'witty',\n",
       "       'interesting or', \"it's bad\", 'with excellent', 'one of great',\n",
       "       'whatever', 'looking', 'either', 'this must see', 'loved',\n",
       "       'br br 4', 'very enjoyable', 'bothered', 'effort', 'recommend',\n",
       "       'movie 2', \"worst movie i've ever\", 'money to', 'somebody',\n",
       "       'as good', 'tragedy', 'idea', 'not enough', 'avoid like',\n",
       "       'come up with', 'watching paint', 'joy to', 'want', 'recommended',\n",
       "       'in love', 'bunch', 'very disappointed', 'affection', 'many',\n",
       "       'thing', 'this worst movie', 'to all', 'see again', 'br highly',\n",
       "       'journey', 'easy', 'what point', 'also very', 'turkey',\n",
       "       'this awful', 'of fun', 'very bad', 'below', 'yet', 'sort of',\n",
       "       'fails', 'but no', 'steals', 'any of characters', 'walked out',\n",
       "       'wondering', 'guy', 'minutes into', 'rare', 'hated', 'movie great',\n",
       "       'film one of', 'to even', 'perfect as', 'interesting but',\n",
       "       'because', 'to cash in on', 'adorable', 'no purpose',\n",
       "       'fascinating', 'does great', 'comedies', 'of worst films ever',\n",
       "       'hours of life', 'nothing new', 'brilliant as', 'most',\n",
       "       'nothing but', 'had high', 'unconvincing', 'not much', 'view',\n",
       "       'flawless', 'watchable', 'so well', 'hour', 'memorable',\n",
       "       'horror movie', 'could go on', 'instead', 'any sense', 'but even',\n",
       "       '4 out of', 'very', 'expertly', 'doing in this', 'not worst',\n",
       "       'moved', 'predictable', 'save money', 'one of best of', '9',\n",
       "       'nothing else', 'piece of', 'of war', 'potential', 'could made',\n",
       "       'day', 'in united', \"there's nothing\", 'not waste time',\n",
       "       'redeeming quality', 'reason', 'flat', 'not that', 'br 8 10',\n",
       "       'relate', 'this thing', 'too many', \"don't miss this\", 'write',\n",
       "       'this junk', 'provides', 'one of', 'innocence', 'avoid this',\n",
       "       'thing about', 'br worst', 'tedious', 'do yourself favor',\n",
       "       'this movie so bad', 'crap br br', 'new york', 'on on', 'sharp',\n",
       "       'contrast', 'would love', 'but great', 'watch this', 'forgettable',\n",
       "       'fantastic', 'acting great', 'reality', 'courage', 'attempts at',\n",
       "       'with bad', 'please', 'in lives', \"wouldn't\", 'episodes',\n",
       "       'br avoid', 'on plus side', 'could been so', 'movie 1', 'idiot',\n",
       "       '9 out', 'do not', 'poorly written', 'delicious', 'idiotic',\n",
       "       'rewarding', 'bad', 'suppose', 'mess of', \"can't wait\",\n",
       "       'this one of', 'disappointing', 'oh god', 'this movie',\n",
       "       'this movie sucks', 'ever seen', \"didn't even\", 'worthless',\n",
       "       'make any', 'to life', '1 out of 10', 'other than', 'tears',\n",
       "       'walked', 'any real', 'emotional', 'way too', 'dramas',\n",
       "       'very funny', '2 out', 'cliché', 'dvd', 'all great', 'been much',\n",
       "       'just stupid', 'nor', 'least', 'pitiful', 'f', 'nothing',\n",
       "       'time with this', 'miss this', 'available', 'in opinion',\n",
       "       'been good', 'well', 'not even worth', 'music by', '7 out',\n",
       "       'spent on', 'should never been', 'noir', \"worst i've\", 'scientist',\n",
       "       'unusual', 'anyone would', '10 out', 'tries', 'even that',\n",
       "       'fails to', 'would love to', 'also', 'story of', 'hell',\n",
       "       'thing can', 'of favorite movies', 'breathtaking', 'bottom',\n",
       "       'themes', 'years later', 'tale', 'city', 'of this movie',\n",
       "       'money on', 'first rate', 'terrible', 'to make movie',\n",
       "       'sat through', 'love with', 'inane', 'br br oh', 'anyway',\n",
       "       'this worst', 'waste time or money', 'poorly executed',\n",
       "       'some great', 'lackluster', 'bad this movie', 'late',\n",
       "       'possibly worst', 'unbelievable', 'skip this', 'b movie',\n",
       "       'surreal', 'wow', 'rest of movie', 'life of', 'just plain bad',\n",
       "       'how bad', 'movies', 'someone', '2 out of', 'piece of crap', '3',\n",
       "       'marriage', 'why would', 'problem with', \"i'd rather\",\n",
       "       'this supposed to be', 'if want to', 'nominated', 'dreck',\n",
       "       'bad this', 'badly', 'atmosphere of', 'frank',\n",
       "       'really enjoyed this', 'horrible', 'young', 'funniest', 'would be',\n",
       "       'performance by', 'brings', 'what waste of', 'trying', 'br br 10',\n",
       "       'deserve', 'incomprehensible', \"don't\", 'contrast to', 'so bad',\n",
       "       'well worth', 'impressed', 'still very', 'looked', 'imdb',\n",
       "       \"it's great\", 'ripped off', 'supposedly', 'stupid br br', 'to do',\n",
       "       'each', 'tremendous', 'instead of', 'at best', 'be seen',\n",
       "       'as great', 'played', 'had', 'wonderful as', 'really liked',\n",
       "       \"doesn't\", 'ok', 'joke', 'this supposed to', 'only reason',\n",
       "       'nothing to do', 'this wonderful', 'one of worst', 'some sort of',\n",
       "       'no', 'illogical', 'br br 2 10', 'nothing in this', 'for this',\n",
       "       'minutes or', 'better', 'hour half', 'br br 10 10', 'unrealistic',\n",
       "       'ralph', 'not recommended', 'so called', 'twists', 'time or money',\n",
       "       'all ages', 'john', 'ed wood', 'all br', 'ages', 'deeper',\n",
       "       'enjoyed', 'any of', 'painful to watch', \"worst movie i've\",\n",
       "       'bad acting bad', 'br 10 10', 'downhill', 'unfortunately',\n",
       "       'br great', 'out of', '10 out of 10', 'actors', 'writing', 'dream',\n",
       "       '9 10', 'utter', 'still', 'simple story', 'first saw this',\n",
       "       'sweet', 'rented', 'mention', 'enough to save', 'vhs', 'say',\n",
       "       'provoking', 'own', \"that's about\", 'producers', 'but just', 'by',\n",
       "       'alright', 'winning', 'what waste', 'accent', 'very weak', 'happy',\n",
       "       'beautiful', 'look like', 'nudity', 'did', 'otherwise', 'movie br',\n",
       "       'live', 'quiet', 'how did', 'holes', 'br br 4 10', 'history',\n",
       "       'truly', 'as ever', 'numbing', 'deep', \"i've ever seen\",\n",
       "       'terrific', 'makes no sense', 'true to', 'movie could been',\n",
       "       'personal', 'to act', 'bad movie', 'international film', '0',\n",
       "       'wretched', 'better off', 'abomination', 'mystery science theater',\n",
       "       'camera', 'acting horrible', 'helps', 'avoid this one',\n",
       "       'enough to', 'than this', \"don't waste money\", 'trite', 'tried to',\n",
       "       'absolutely nothing to', 'paper', 'years', 'falls flat',\n",
       "       'as always', 'did great job', 'lame', 'watch again again',\n",
       "       'rating', 'one of funniest', 'dud', 'growing up', 'sequel',\n",
       "       'except', 'br br 7', 'nevertheless', 'worst movie', 'attempt at',\n",
       "       'decided to', 'does great job', 'better than this', '9 out of',\n",
       "       'bunch of', 'poor', 'worst films', 'wrong', 'another great',\n",
       "       'worst of all', 'wanted to', 'animation', 'only thing that',\n",
       "       'to be funny', \"let's\", 'br grade d', 'beautifully',\n",
       "       'total waste of time', 'of love', 'james', 'not scary',\n",
       "       'this mess', 'one good', 'bin', 'really really bad',\n",
       "       'extraordinary'], dtype=object)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = CountVectorizer(\n",
    "    ngram_range=(1, 4)               # Use 1- to 4-grams\n",
    ")\n",
    "\n",
    "vectorizer2.fit(top_vocab)\n",
    "dtm_train2 = vectorizer2.transform(df_train['review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_test2= vectorizer2.transform(df_test_x['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x1336 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1565106 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '10 10', '10 out', ..., 'young man', 'yourself',\n",
       "       'yourself favor'], dtype=object)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0.01, 0.5, 20)\n",
    "ridge_model = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "ridge_clf = GridSearchCV(ridge_model, [{'C': alphas}], cv=n_folds, refit=False, scoring='roc_auc')\n",
    "ridge_clf.fit(X=dtm_train2, y=df_train['sentiment'])\n",
    "best_alpha = ridge_clf.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.946826279956344"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = ridge_clf.best_params_['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29368421052631577"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-34 {color: black;}#sk-container-id-34 pre{padding: 0;}#sk-container-id-34 div.sk-toggleable {background-color: white;}#sk-container-id-34 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-34 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-34 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-34 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-34 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-34 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-34 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-34 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-34 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-34 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-34 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-34 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-34 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-34 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-34 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-34 div.sk-item {position: relative;z-index: 1;}#sk-container-id-34 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-34 div.sk-item::before, #sk-container-id-34 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-34 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-34 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-34 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-34 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-34 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-34 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-34 div.sk-label-container {text-align: center;}#sk-container-id-34 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-34 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-34\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.29368421052631577, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" checked><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.29368421052631577, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.29368421052631577, solver='liblinear')"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ridge_model = LogisticRegression(penalty='l2', solver='liblinear', C = best_alpha)\n",
    "best_ridge_model.fit(X=dtm_train2, y=df_train['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The probability estimates correspond to the probability of the class with the greater label, i.e. estimator.classes_[1] \n",
    "and thus estimator.predict_proba(X, y)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9484156249279397"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df_test_y['sentiment'].values, best_ridge_model.predict_proba(dtm_test2)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
